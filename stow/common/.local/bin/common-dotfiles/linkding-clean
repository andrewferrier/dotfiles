#!/usr/bin/env -S uv run --project ${HOME}/.local/bin/common-dotfiles --script
# vim: set ft=python:
import argparse
import html
import logging
import re
import sys
import urllib.parse
from dataclasses import dataclass
from typing import Any, Literal

import requests
from tqdm import tqdm


@dataclass
class ValidationResult:
    is_valid: bool
    reason: str


logger = logging.getLogger("linkding-clean")
logger.propagate = False
logger.setLevel(logging.INFO)  # Changed default level to INFO

syserr_handler = logging.StreamHandler(stream=sys.stderr)
syserr_handler.setLevel(logging.INFO)  # Changed default level to INFO
syserr_handler.setFormatter(logging.Formatter("%(levelname)s: %(message)s"))
logger.addHandler(syserr_handler)


class LinkdingAPIClient:
    def __init__(self, base_url: str, token: str) -> None:
        if not base_url.endswith("/"):
            base_url += "/"
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({"Authorization": f"Token {token}"})
        logger.debug(f"LinkdingAPIClient initialized with base_url: {self.base_url}")

    def get_bookmarks(self, archived: bool = False) -> Any:  # noqa: ANN401, FBT001, FBT002
        endpoint = "archived/" if archived else ""
        url = f"{self.base_url}bookmarks/{endpoint}?limit=100000"
        logger.debug(
            f"Fetching {'archived' if archived else 'unarchived'} bookmarks from: {url}"
        )
        response = self.session.get(url)
        response.raise_for_status()
        data = response.json()
        return data["results"]

    def archive_bookmark(self, bookmark_id: int) -> None:
        url = f"{self.base_url}bookmarks/{bookmark_id}/archive/"
        response = self.session.post(url)
        response.raise_for_status()
        logger.debug(f"Successfully archived bookmark ID: {bookmark_id}")

    def unarchive_bookmark(self, bookmark_id: int) -> None:
        url = f"{self.base_url}bookmarks/{bookmark_id}/unarchive/"
        response = self.session.post(url)
        response.raise_for_status()
        logger.debug(f"Successfully unarchived bookmark ID: {bookmark_id}")

    def delete_bookmark(self, bookmark_id: int) -> None:
        url = f"{self.base_url}bookmarks/{bookmark_id}/"
        response = self.session.delete(url)
        response.raise_for_status()
        logger.debug(f"Successfully deleted bookmark ID: {bookmark_id}")

    def update_bookmark(
        self, bookmark_id: int, title: str | None = None, url: str | None = None
    ) -> None:
        url_path = f"{self.base_url}bookmarks/{bookmark_id}/"
        payload = {}
        if title is not None:
            payload["title"] = title
        if url is not None:
            payload["url"] = url

        if not payload:
            logger.debug(f"No update data provided for bookmark ID: {bookmark_id}")
            return

        logger.info(f"Updating bookmark ID: {bookmark_id} with payload: {payload}")
        response = self.session.patch(url_path, json=payload)
        response.raise_for_status()
        logger.debug(f"Successfully updated bookmark ID: {bookmark_id}")

    def get_remote_metadata(self, url: str) -> dict[str, Any] | None:
        escaped_url = urllib.parse.quote_plus(url)
        check_url = f"http://192.168.1.10:8084/api/bookmarks/check/?url={escaped_url}"
        logger.debug(f"Checking remote metadata for URL: {url} using {check_url}")
        try:
            response = self.session.get(check_url, timeout=30)
            response.raise_for_status()
            data = response.json()
            return data.get("metadata")
        except requests.exceptions.ReadTimeout:
            logger.warning(
                f"Read timeout when fetching remote metadata for URL: {url}. Skipping."
            )
            return None


def _clean_bookmark_title(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    original_title: str = bookmark.get("title", "")
    bookmark_url: str = bookmark["url"]

    compare_len = min(len(original_title), len(bookmark_url), 20)

    title_prefix_for_comparison = original_title[:compare_len]
    url_prefix_for_comparison = bookmark_url[:compare_len]

    if (not original_title) or title_prefix_for_comparison == url_prefix_for_comparison:
        try:
            metadata = client.get_remote_metadata(bookmark_url)
            fetched_title = metadata.get("title") if metadata else None

            if fetched_title and fetched_title != original_title:
                if dry_run:
                    logger.info(
                        f"DRY RUN: Would update title for bookmark ID: {bookmark_id} "
                        f"from '{original_title}' to '{fetched_title}' "
                        "(from remote metadata)."
                    )
                else:
                    logger.info(
                        f"Updating title for bookmark ID: {bookmark_id} "
                        f"from '{original_title}' to '{fetched_title}' "
                        "(from remote metadata)."
                    )
                    client.update_bookmark(bookmark_id, title=fetched_title)
        except requests.exceptions.RequestException:
            logger.error(  # noqa: TRY400
                f"Failed to fetch metadata from remote for bookmark ID: {bookmark_id}, "
                f"URL: {bookmark_url}"
            )
        return

    cleaned_title = html.unescape(original_title)

    if cleaned_title != original_title:
        if dry_run:
            logger.info(
                f"DRY RUN: Would update title for bookmark ID: {bookmark_id} "
                f"from '{original_title}' to '{cleaned_title}'",
            )
        else:
            try:
                logger.info(
                    f"Updating title for bookmark ID: {bookmark_id} "
                    f"from '{original_title}' to '{cleaned_title}'",
                )
                client.update_bookmark(bookmark_id, title=cleaned_title)
            except requests.exceptions.RequestException:
                logger.error(f"Failed to update title for bookmark ID: {bookmark_id}")  # noqa: TRY400


def _perform_bookmark_action(
    client: LinkdingAPIClient,
    bookmark_id: int,
    url: str,
    action_type: Literal["archive", "delete", "unarchive"],
    dry_run: bool,  # noqa: FBT001
    validation_reason: str,
) -> None:
    if dry_run:
        logger.info(
            f"DRY RUN: Would {action_type} bookmark ID: {bookmark_id}, URL: {url} "
            f"because {validation_reason}",
        )
    else:
        try:
            logger.info(
                f"ACTION: {action_type} bookmark ID: {bookmark_id}, URL: {url} "
                f" because {validation_reason}",
            )
            if action_type == "delete":
                client.delete_bookmark(bookmark_id)
            elif action_type == "archive":
                client.archive_bookmark(bookmark_id)
            elif action_type == "unarchive":
                client.unarchive_bookmark(bookmark_id)
        except requests.exceptions.RequestException:
            logger.error(  # noqa: TRY400
                f"Failed to {action_type} bookmark ID: {bookmark_id}, URL: {url}",
            )


def _is_bookmark_valid(
    bookmark: dict, allow_redirects: bool = False
) -> ValidationResult:
    url: str = bookmark["url"]
    is_valid = True
    reason = "Valid"

    try:
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chromium/133.0.5008.159 "
                "Chrome/133.0.5008.159 Safari/537.36"
            )
        }

        r = requests.get(
            url, headers=headers, allow_redirects=allow_redirects, timeout=20
        )
        status_code = r.status_code

        if status_code is None:
            is_valid = False
            reason = "no status code"
        elif status_code >= 300 and (not allow_redirects):  # noqa: PLR2004
            is_valid = False
            reason = (
                f"HTTP status code {status_code}: redirect without allow_redirects."
            )
        elif status_code >= 400:  # noqa: PLR2004
            is_valid = False
            reason = f"HTTP status code {status_code}."

    except requests.exceptions.RequestException as e:
        is_valid = False
        reason = f"RequestException: {e}"

    return ValidationResult(is_valid=is_valid, reason=reason)


EVALUATE_REDIRECT_REGEXES = re.compile(r"^https://getpocket\.com:443/explore/item/")


def _resolve_redirected_url(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    original_url: str = bookmark["url"]

    if EVALUATE_REDIRECT_REGEXES.match(original_url):
        logger.debug(f"URL matches redirect pattern: {original_url}")
        try:
            r = requests.get(original_url, timeout=20, allow_redirects=True)
            r.raise_for_status()

            final_url = r.url

            if final_url != original_url:
                if dry_run:
                    logger.info(
                        f"DRY RUN: Would update URL for bookmark ID: {bookmark_id} "
                        f"from '{original_url}' to '{final_url}'",
                    )
                else:
                    try:
                        logger.info(
                            f"Updating URL for bookmark ID: {bookmark_id} "
                            f"from '{original_url}' to '{final_url}'",
                        )
                        client.update_bookmark(bookmark_id, url=final_url)
                    except requests.exceptions.RequestException:
                        logger.error(  # noqa: TRY400
                            f"Failed to update URL for bookmark ID: {bookmark_id}"
                        )
            else:
                logger.debug(f"URL {original_url} did not redirect.")

        except requests.exceptions.RequestException:
            logger.error(  # noqa: TRY400
                f"Failed to resolve redirects for URL: {original_url} "
                f"(ID: {bookmark_id})"
            )


def _process_archived_bookmark(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    url: str = bookmark["url"]
    title: str = bookmark.get("title", "")

    logger.debug(
        f"Processing archived bookmark ID: {bookmark_id}, URL: {url}, title: {title}"
    )

    validation_result = _is_bookmark_valid(bookmark)
    if validation_result.is_valid:
        _perform_bookmark_action(
            client, bookmark_id, url, "unarchive", dry_run, validation_result.reason
        )
    else:
        logger.debug(
            f"Archived bookmark ID: {bookmark_id} (URL: {url}) is still invalid. "
            f"Reason: {validation_result.reason}"
        )


def _process_unarchived_bookmark(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
    delete_bookmark: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    url: str = bookmark["url"]
    title: str = bookmark.get("title", "")

    logger.debug(f"Processing bookmark ID: {bookmark_id}, URL: {url}, title: {title}")

    action_verb = "delete" if delete_bookmark else "archive"

    validation_result = _is_bookmark_valid(bookmark, allow_redirects=True)
    if validation_result.is_valid:
        _clean_bookmark_title(client, bookmark, dry_run)
        _resolve_redirected_url(client, bookmark, dry_run)
    else:
        _perform_bookmark_action(
            client, bookmark_id, url, action_verb, dry_run, validation_result.reason
        )


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Clean Linkding bookmarks by archiving or deleting invalid ones.",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Do not archive or delete bookmarks, just show what would be done.",
    )
    parser.add_argument(
        "--delete",
        action="store_true",
        help="Delete bookmarks instead of archiving them.",
    )
    parser.add_argument(
        "--base-url",
        required=True,
        help="Linkding API base URL (e.g., https://linkding.example.com/api/).",
    )
    parser.add_argument(
        "--token",
        required=True,
        help="Linkding API token. Defaults to LINKDING_API_TOKEN environment variable.",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose output (DEBUG level).",
    )
    args = parser.parse_args()

    if args.verbose:
        logger.setLevel(logging.DEBUG)
        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)

    client = LinkdingAPIClient(args.base_url, args.token)

    logger.info("Starting Linkding bookmark cleaning process...")
    try:
        unarchived_bookmarks = client.get_bookmarks(archived=False)
        for bookmark in tqdm(
            unarchived_bookmarks,
            desc="Processing unarchived bookmarks",
            unit="bookmark",
            smoothing=0,
        ):
            _process_unarchived_bookmark(client, bookmark, args.dry_run, args.delete)

        archived_bookmarks = client.get_bookmarks(archived=True)
        for bookmark in tqdm(
            archived_bookmarks,
            desc="Processing archived bookmarks",
            unit="bookmark",
            smoothing=0,
        ):
            _process_archived_bookmark(client, bookmark, args.dry_run)

    except requests.exceptions.RequestException as e:
        logger.critical(f"Failed to interact with Linkding API: {e}")
        sys.exit(1)

    logger.info("Linkding bookmark cleaning process finished.")


if __name__ == "__main__":
    main()
