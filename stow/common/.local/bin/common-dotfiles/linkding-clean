#!/usr/bin/env -S uv run --project ${HOME}/.local/bin/common-dotfiles --script
# vim: set ft=python:

import argparse
import html
import logging
import re
import sys
from typing import Any

import requests
from tqdm import tqdm

logger = logging.getLogger("linkding-clean")
logger.propagate = False
logger.setLevel(logging.INFO)  # Changed default level to INFO

syserr_handler = logging.StreamHandler(stream=sys.stderr)
syserr_handler.setLevel(logging.INFO)  # Changed default level to INFO
syserr_handler.setFormatter(logging.Formatter("%(levelname)s: %(message)s"))
logger.addHandler(syserr_handler)


class LinkdingAPIClient:
    def __init__(self, base_url: str, token: str) -> None:
        if not base_url.endswith("/"):
            base_url += "/"
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({"Authorization": f"Token {token}"})
        logger.debug(f"LinkdingAPIClient initialized with base_url: {self.base_url}")

    def get_unarchived_bookmarks(self) -> Any:  # noqa: ANN401
        url = f"{self.base_url}bookmarks/?limit=100000"
        logger.debug(f"Fetching results from: {url}")
        response = self.session.get(url)
        response.raise_for_status()  # Raise an exception for HTTP errors (4xx or 5xx)
        data = response.json()
        return data["results"]

    def archive_bookmark(self, bookmark_id: int) -> None:
        url = f"{self.base_url}bookmarks/{bookmark_id}/archive/"
        logger.info(f"Archiving bookmark ID: {bookmark_id}")
        response = self.session.post(url)
        response.raise_for_status()
        logger.debug(f"Successfully archived bookmark ID: {bookmark_id}")

    def delete_bookmark(self, bookmark_id: int) -> None:
        url = f"{self.base_url}bookmarks/{bookmark_id}/"
        logger.info(f"Deleting bookmark ID: {bookmark_id}")
        response = self.session.delete(url)
        response.raise_for_status()
        logger.debug(f"Successfully deleted bookmark ID: {bookmark_id}")

    def update_bookmark(
        self, bookmark_id: int, title: str | None = None, url: str | None = None
    ) -> None:
        url_path = f"{self.base_url}bookmarks/{bookmark_id}/"
        payload = {}
        if title is not None:
            payload["title"] = title
        if url is not None:
            payload["url"] = url

        if not payload:
            logger.debug(f"No update data provided for bookmark ID: {bookmark_id}")
            return

        logger.info(f"Updating bookmark ID: {bookmark_id} with payload: {payload}")
        response = self.session.patch(url_path, json=payload)
        response.raise_for_status()
        logger.debug(f"Successfully updated bookmark ID: {bookmark_id}")


def _clean_bookmark_title(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    original_title: str = bookmark.get("title", "")

    if original_title.startswith("http://"):
        logger.debug(
            f"Skipping title cleaning for bookmark ID: {bookmark_id} "
            f"as it starts with 'http://'."
        )
        return

    cleaned_title = html.unescape(original_title)

    if cleaned_title != original_title:
        if dry_run:
            logger.info(
                f"Dry run: Would update title for bookmark ID: {bookmark_id} "
                f"from '{original_title}' to '{cleaned_title}'",
            )
        else:
            try:
                logger.info(
                    f"Updating title for bookmark ID: {bookmark_id} "
                    f"from '{original_title}' to '{cleaned_title}'",
                )
                client.update_bookmark(bookmark_id, title=cleaned_title)
            except requests.exceptions.RequestException:
                logger.exception(
                    f"Failed to update title for bookmark ID: {bookmark_id}"
                )


def _check_bookmark_validity(
    client: LinkdingAPIClient,
    bookmark: dict,
    delete_bookmark: bool,  # noqa: FBT001
    dry_run: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    url: str = bookmark["url"]
    invalid = False

    action_verb = "delete" if delete_bookmark else "archive"

    try:
        # Use requests.get directly without the client's session for external URL checks
        # to avoid sharing authentication headers or other unnecessary overhead.
        r = requests.get(url, timeout=20)

        if r.status_code == 404:  # noqa: PLR2004
            logger.warning(
                f"URL {url} (ID: {bookmark_id}) returned 404, "
                f"marking for {action_verb}.",
            )
            invalid = True

    except requests.exceptions.ConnectionError:
        logger.error(  # noqa: TRY400
            f"Connection error for {url} (ID: {bookmark_id}), "
            f"marking for {action_verb}.",
        )
        invalid = True
    except requests.exceptions.ReadTimeout:
        logger.error(  # noqa: TRY400
            f"Read timeout for {url} (ID: {bookmark_id}), skipping.",
        )
    except requests.exceptions.TooManyRedirects:
        logger.error(  # noqa: TRY400
            f"Too many redirects for {url} (ID: {bookmark_id}), skipping.",
        )
    except requests.exceptions.RequestException:
        logger.error(  # noqa: TRY400
            f"Unexpected request error for {url} (ID: {bookmark_id}), skipping.",
        )

    if invalid:
        if dry_run:
            logger.info(
                f"Dry run: Would {action_verb} bookmark ID: {bookmark_id}, URL: {url}",
            )
        else:
            try:
                if delete_bookmark:
                    client.delete_bookmark(bookmark_id)
                else:
                    client.archive_bookmark(bookmark_id)
            except requests.exceptions.RequestException:
                logger.exception(
                    f"Failed to {action_verb} bookmark ID: {bookmark_id}, URL: {url}",
                )


EVALUATE_REDIRECT_REGEXES = re.compile(r"^https://getpocket\.com:443/explore/item/")


def _resolve_redirects(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    original_url: str = bookmark["url"]

    if EVALUATE_REDIRECT_REGEXES.match(original_url):
        logger.debug(f"URL matches redirect pattern: {original_url}")
        try:
            r = requests.get(original_url, timeout=20, allow_redirects=True)
            r.raise_for_status()

            final_url = r.url

            if final_url != original_url:
                if dry_run:
                    logger.info(
                        f"Dry run: Would update URL for bookmark ID: {bookmark_id} "
                        f"from '{original_url}' to '{final_url}'",
                    )
                else:
                    try:
                        logger.info(
                            f"Updating URL for bookmark ID: {bookmark_id} "
                            f"from '{original_url}' to '{final_url}'",
                        )
                        client.update_bookmark(bookmark_id, url=final_url)
                    except requests.exceptions.RequestException:
                        logger.exception(
                            f"Failed to update URL for bookmark ID: {bookmark_id}"
                        )
            else:
                logger.debug(f"URL {original_url} did not redirect.")

        except requests.exceptions.RequestException:
            logger.exception(
                f"Failed to resolve redirects for URL: {original_url} "
                f"(ID: {bookmark_id})"
            )


def process_bookmark(
    client: LinkdingAPIClient,
    bookmark: dict,
    dry_run: bool,  # noqa: FBT001
    delete_bookmark: bool,  # noqa: FBT001
) -> None:
    bookmark_id: int = bookmark["id"]
    url: str = bookmark["url"]
    title: str = bookmark.get("title", "")

    logger.debug(f"Processing bookmark ID: {bookmark_id}, URL: {url}, title: {title}")

    _clean_bookmark_title(client, bookmark, dry_run)
    _resolve_redirects(client, bookmark, dry_run)
    _check_bookmark_validity(client, bookmark, delete_bookmark, dry_run)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Clean Linkding bookmarks by archiving or deleting invalid ones.",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Do not archive or delete bookmarks, just show what would be done.",
    )
    parser.add_argument(
        "--delete",
        action="store_true",
        help="Delete bookmarks instead of archiving them.",
    )
    parser.add_argument(
        "--base-url",
        required=True,
        help="Linkding API base URL (e.g., https://linkding.example.com/api/).",
    )
    parser.add_argument(
        "--token",
        required=True,
        help="Linkding API token. Defaults to LINKDING_API_TOKEN environment variable.",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose output (DEBUG level).",
    )
    args = parser.parse_args()

    if args.verbose:
        logger.setLevel(logging.DEBUG)
        for handler in logger.handlers:
            handler.setLevel(logging.DEBUG)

    client = LinkdingAPIClient(args.base_url, args.token)

    logger.info("Starting Linkding bookmark cleaning process...")
    try:
        bookmarks = client.get_unarchived_bookmarks()
        for bookmark in tqdm(bookmarks, desc="Processing bookmarks", unit="bookmark"):
            process_bookmark(client, bookmark, args.dry_run, args.delete)

    except requests.exceptions.RequestException as e:
        logger.critical(f"Failed to fetch bookmarks from Linkding API: {e}")
        sys.exit(1)

    logger.info("Linkding bookmark cleaning process finished.")


if __name__ == "__main__":
    main()
